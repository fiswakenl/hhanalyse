#!/usr/bin/env python3
"""
–ö–ª–∞—Å—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å—Ç–µ–∫–æ–≤ –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–π —Å –ø–æ–º–æ—â—å—é LLM.
"""

import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Any
import pandas as pd
from openai import OpenAI


class TechnologyExtractor:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å—Ç–µ–∫–∏ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–π —Å –ø–æ–º–æ—â—å—é LLM."""
    
    def __init__(self, api_key: str, model: str = "openai/gpt-oss-20b:free", batch_size: int = 5):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.
        
        Args:
            api_key: API –∫–ª—é—á OpenRouter
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            batch_size: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
        """
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key
        )
        self.model = model
        self.batch_size = batch_size
        
        # –ë–∞–∑–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–±—É–¥—É—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å—Å—è)
        self.base_categories = {
            "fe_framework": ["React", "Vue", "Angular", "Svelte", "Next.js"],
            "state_mgmt": ["Redux", "MobX", "Zustand", "RTK Query", "Pinia"],
            "styling": ["Tailwind", "SCSS", "Styled Components", "CSS Modules", "MUI"],
            "testing": ["Jest", "Cypress", "Playwright", "RTL", "Vitest"],
            "api_proto": ["REST", "GraphQL", "WebSocket", "tRPC"],
            "ts_required": ["–¥–∞", "–Ω–µ—Ç", "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"],
            "business_domain": ["—Ñ–∏–Ω—Ç–µ—Ö", "e-commerce", "–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ", "–º–µ–¥—Ç–µ—Ö", "–≥–µ–π–º–¥–µ–≤"],
            "company_type": ["–ø—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è", "–∞—É—Ç—Å–æ—Ä—Å", "–∞—É—Ç—Å—Ç–∞—Ñ—Ñ", "–≤–µ–±-—Å—Ç—É–¥–∏—è", "—Å—Ç–∞—Ä—Ç–∞–ø"]
        }
        
        # –ö–æ–ª–æ–Ω–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –¥–æ–ø–æ–ª–Ω—è—Ç—å—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ (–º–∞—Å—Å–∏–≤—ã)
        self.dynamic_categories = ["fe_framework", "state_mgmt", "styling", "testing", "api_proto"]
        # –ö–æ–ª–æ–Ω–∫–∏ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (—Å—Ç—Ä–æ–∫–∏)
        self.fixed_categories = ["ts_required", "business_domain", "company_type"]
        
        # –î–û–°–¢–£–ü–ù–´–ï –ú–û–î–ï–õ–ò (–º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –∑–¥–µ—Å—å)
        self.available_models = {
            "free": "openai/gpt-oss-20b:free",
            "haiku": "anthropic/claude-3-5-haiku",
            "sonnet": "anthropic/claude-3-5-sonnet", 
            "llama": "meta-llama/llama-3.1-8b-instruct",
            "gemini": "google/gemini-flash-1.5",
            "qwen": "qwen/qwen-2.5-72b-instruct"
        }
        print(f"üí° –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {list(self.available_models.keys())}")
        print(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: {model}")
    
    def load_existing_categories(self, df: pd.DataFrame, start_idx: int) -> Dict[str, List[str]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è."""
        categories = self.base_categories.copy()
        
        # –ù–∞—Ö–æ–¥–∏–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (—Ç–µ —á—Ç–æ –∏–º–µ—é—Ç –∫–æ–ª–æ–Ω–∫—É extracted_at)
        if 'extracted_at' in df.columns:
            processed_df = df[df['extracted_at'].notna()].iloc[:start_idx]
            
            if not processed_df.empty:
                print(f"–ù–∞–π–¥–µ–Ω–æ {len(processed_df)} —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π, –ø–æ–ø–æ–ª–Ω—è—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∏...")
                
                # –ü–æ–ø–æ–ª–Ω—è–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–º–∞—Å—Å–∏–≤—ã)
                for category in self.dynamic_categories:
                    if category in processed_df.columns:
                        existing_values = set()
                        for row in processed_df[category]:
                            if pd.notna(row) and row:
                                try:
                                    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ JSON –º–∞—Å—Å–∏–≤
                                    values = json.loads(row) if isinstance(row, str) else row
                                    if isinstance(values, list):
                                        existing_values.update(values)
                                except (json.JSONDecodeError, TypeError):
                                    pass
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫ –±–∞–∑–æ–≤—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                        if existing_values:
                            categories[category] = sorted(set(categories[category]) | existing_values)
                            print(f"  {category}: +{len(existing_values - set(self.base_categories[category]))} –Ω–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
                
                # –ü–æ–ø–æ–ª–Ω—è–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Å—Ç—Ä–æ–∫–∏)
                for category in self.fixed_categories:
                    if category in processed_df.columns:
                        existing_values = set(processed_df[category].dropna().unique())
                        if existing_values:
                            categories[category] = sorted(set(categories[category]) | existing_values)
        
        return categories
    
    def format_prompt(self, vacancies: List[Dict], categories: Dict[str, List[str]]) -> str:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ –∏ —Ç–µ–∫—É—â–∏–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏."""
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        categories_text = ""
        for category, values in categories.items():
            values_str = '", "'.join(values[:10])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
            more_text = f" (–∏ –µ—â–µ {len(values)-10})" if len(values) > 10 else ""
            categories_text += f"- {category}: [\"{values_str}\"]{more_text}\n"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–π
        vacancies_data = []
        for vacancy in vacancies:
            vacancy_data = {
                "vacancy_id": str(vacancy.get('id', '')),
                "name": vacancy.get('name', ''),
                "employer_name": vacancy.get('employer_name', ''),
                "key_skills": vacancy.get('key_skills', []),
                "description": (vacancy.get('description_markdown', '') or vacancy.get('description', ''))[:1500],
                "branded_description": (vacancy.get('branded_description_markdown', '') or vacancy.get('branded_description', ''))[:800]
            }
            vacancies_data.append(vacancy_data)
        
        prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –≤–∞–∫–∞–Ω—Å–∏–π –≤ IT. –ò–∑–≤–ª–µ–∫–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å—Ç–µ–∫–∏ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–æ–º–ø–∞–Ω–∏–π –∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π.

–ê–ù–ê–õ–ò–ó–ò–†–£–ô –≠–¢–ò –ü–û–õ–Ø –ö–ê–ñ–î–û–ô –í–ê–ö–ê–ù–°–ò–ò:
- "name" - –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, —É—Ä–æ–≤–µ–Ω—å)
- "description" - –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –∑–∞–¥–∞—á–∏
- "key_skills" - —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –Ω–∞–≤—ã–∫–∏
- "branded_description" - –æ–ø–∏—Å–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –∏ –µ—ë –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- "employer_name" - –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è

–°–£–©–ï–°–¢–í–£–Æ–©–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ò (–∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö, –µ—Å–ª–∏ –ø–æ–¥—Ö–æ–¥—è—Ç, –∏–Ω–∞—á–µ —Å–æ–∑–¥–∞–≤–∞–π –Ω–æ–≤—ã–µ):
{categories_text}

–°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê:
1. –î–ª—è —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π (fe_framework, state_mgmt, styling, testing, api_proto) - –≤—ã–±–∏—Ä–∞–π –í–°–ï –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –≤ –º–∞—Å—Å–∏–≤
2. –î–ª—è ts_required, business_domain, company_type - –û–î–ù–£ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
3. –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –ù–ï –ø–æ–¥—Ö–æ–¥–∏—Ç - —Å–æ–∑–¥–∞–π –Ω–æ–≤—É—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é
4. –í—Å–µ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω—è–π –í–°–ï –ø–æ–ª—è
5. –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –º–∞—Å—Å–∏–≤–æ–º, –ë–ï–ó –æ–±—ä—è—Å–Ω–µ–Ω–∏–π, –ë–ï–ó –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –ë–ï–ó markdown

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ô –§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê - –¢–û–õ–¨–ö–û —ç—Ç–æ—Ç JSON –º–∞—Å—Å–∏–≤:
[
  {{
    "vacancy_id": "123822218",
    "fe_framework": ["Vue", "Next.js"],
    "state_mgmt": ["Redux"],
    "styling": ["Bootstrap"],
    "testing": ["Jest"],
    "api_proto": ["REST"],
    "ts_required": "–Ω–µ—Ç",
    "business_domain": "–≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞",
    "company_type": "–≤–µ–±-—Å—Ç—É–¥–∏—è"
  }}
]

–ù–ï –î–û–ë–ê–í–õ–Ø–ô:
- –ù–∏–∫–∞–∫–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π
- –ù–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
- –ù–∏–∫–∞–∫–∏—Ö markdown –±–ª–æ–∫–æ–≤ (```json)
- –ù–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞

–ù–ê–ß–ù–ò –û–¢–í–ï–¢ –°–û –°–ò–ú–í–û–õ–ê [ –ò –ó–ê–ö–û–ù–ß–ò –°–ò–ú–í–û–õ–û–ú ]

–í–ê–ö–ê–ù–°–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{json.dumps(vacancies_data, ensure_ascii=False, indent=2)}

–û–¢–í–ï–¢:"""

        return prompt
    
    def extract_batch(self, batch: List[Dict], categories: Optional[Dict[str, List[str]]] = None) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏–∑ –±–∞—Ç—á–∞ –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ OpenRouter API."""
        if not batch:
            return []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–ª–∏ –±–∞–∑–æ–≤—ã–µ
        if categories is None:
            categories = self.base_categories
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        prompt = self.format_prompt(batch, categories)
        
        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenRouter API —Å retry –ª–æ–≥–∏–∫–æ–π
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"–û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ {self.model} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")
                
                response = self.client.chat.completions.create(
                    extra_headers={
                        "HTTP-Referer": "https://github.com/hhscribe",
                        "X-Title": "HH Scribe Tech Extractor",
                    },
                    model=self.model,
                    messages=[
                        {
                            "role": "user", 
                            "content": prompt
                        }
                    ],
                    temperature=0.1,
                    max_tokens=4000
                )
                
                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
                llm_response = response.choices[0].message.content
                print(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–æ–π {len(llm_response)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                extracted_data = self.parse_llm_response(llm_response)
                
                if extracted_data:
                    print(f"–£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(extracted_data)} –∑–∞–ø–∏—Å–µ–π")
                    return extracted_data
                else:
                    print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                    
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # Exponential backoff
                    print(f"–ñ–¥–µ–º {wait_time} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                    time.sleep(wait_time)
        
        print("–ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫, –≤–æ–∑–≤—Ä–∞—â–∞—é –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        return []
    
    def parse_llm_response(self, response: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
        if not response or not response.strip():
            print("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç LLM")
            return []
        
        # –ò—â–µ–º JSON –±–ª–æ–∫ –≤ –æ—Ç–≤–µ—Ç–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–µ—Ä–Ω—É—Ç –≤ ```json –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ [])
        json_text = response.strip()
        
        # –£–¥–∞–ª—è–µ–º markdown –∫–æ–¥ –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if "```json" in json_text:
            start = json_text.find("```json") + 7
            end = json_text.find("```", start)
            if end != -1:
                json_text = json_text[start:end].strip()
        elif "```" in json_text:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±–æ–π –∫–æ–¥ –±–ª–æ–∫
            start = json_text.find("```") + 3
            end = json_text.find("```", start)
            if end != -1:
                json_text = json_text[start:end].strip()
        
        # –ò—â–µ–º JSON –º–∞—Å—Å–∏–≤ –≤ —Ç–µ–∫—Å—Ç–µ
        start_bracket = json_text.find('[')
        end_bracket = json_text.rfind(']')
        
        if start_bracket != -1 and end_bracket != -1 and end_bracket > start_bracket:
            json_text = json_text[start_bracket:end_bracket + 1]
        
        try:
            # –ü–∞—Ä—Å–∏–º JSON
            data = json.loads(json_text)
            
            if not isinstance(data, list):
                print(f"–û–∂–∏–¥–∞–ª—Å—è JSON –º–∞—Å—Å–∏–≤, –ø–æ–ª—É—á–µ–Ω {type(data)}")
                return []
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
            validated_data = []
            for item in data:
                if not isinstance(item, dict):
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞—é –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç: {item}")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                if 'vacancy_id' not in item:
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞—é —ç–ª–µ–º–µ–Ω—Ç –±–µ–∑ vacancy_id: {item}")
                    continue
                
                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∏ –æ—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                validated_item = {
                    'vacancy_id': str(item['vacancy_id']),
                    'fe_framework': item.get('fe_framework', []),
                    'state_mgmt': item.get('state_mgmt', []),
                    'styling': item.get('styling', []),
                    'testing': item.get('testing', []),
                    'api_proto': item.get('api_proto', []),
                    'ts_required': item.get('ts_required', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ'),
                    'business_domain': item.get('business_domain', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ'),
                    'company_type': item.get('company_type', '–Ω–µ —É–∫–∞–∑–∞–Ω–æ'),
                    'extracted_at': datetime.now().isoformat()
                }
                
                # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –º–∞—Å—Å–∏–≤—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –º–∞—Å—Å–∏–≤—ã
                for array_field in self.dynamic_categories:
                    if not isinstance(validated_item[array_field], list):
                        validated_item[array_field] = []
                
                validated_data.append(validated_item)
            
            print(f"–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–æ {len(validated_data)} –∏–∑ {len(data)} –∑–∞–ø–∏—Å–µ–π")
            return validated_data
            
        except json.JSONDecodeError as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            print(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π —Ç–µ–∫—Å—Ç: {json_text[:500]}...")
            return []
        except Exception as e:
            print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
            return []
    
    def process_range(self, start: int, end: int, input_path: str, output_path: str) -> None:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –≤–∞–∫–∞–Ω—Å–∏–π –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
        print(f"–ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ {input_path}...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
        try:
            df = pd.read_parquet(input_path)
            print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –≤–∞–∫–∞–Ω—Å–∏–π")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω
        if start < 0 or end > len(df) or start >= end:
            print(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: start={start}, end={end}, –≤—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π={len(df)}")
            return
        
        # –í—ã–±–∏—Ä–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        process_df = df.iloc[start:end].copy()
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞–∫–∞–Ω—Å–∏–∏ {start}-{end} ({len(process_df)} –∑–∞–ø–∏—Å–µ–π)")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è
        print("–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏...")
        current_categories = self.load_existing_categories(df, start)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –±–∞—Ç—á–∏
        all_results = []
        total_batches = (len(process_df) + self.batch_size - 1) // self.batch_size
        
        for i in range(0, len(process_df), self.batch_size):
            batch_num = i // self.batch_size + 1
            batch_df = process_df.iloc[i:i + self.batch_size]
            
            print(f"\nüì¶ –ë–∞—Ç—á {batch_num}/{total_batches} (–∑–∞–ø–∏—Å–∏ {start + i}-{start + i + len(batch_df) - 1})")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –¥–ª—è API
            batch_data = []
            for _, row in batch_df.iterrows():
                batch_data.append(row.to_dict())
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –±–∞—Ç—á–µ–º (–¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è)
            if i > 0:  # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
                current_categories = self.load_existing_categories(df, start + i)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ LLM —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
            batch_results = self.extract_batch(batch_data, current_categories)
            
            if batch_results:
                print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(batch_results)} –∑–∞–ø–∏—Å–µ–π –≤ –±–∞—Ç—á–µ {batch_num}")
                all_results.extend(batch_results)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–π DataFrame
                self._update_dataframe_with_results(df, batch_results, start + i)
                
            else:
                print(f"‚ùå –ë–∞—Ç—á {batch_num} –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å")
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(1)
        
        if all_results:
            print(f"\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(all_results)} –∑–∞–ø–∏—Å–µ–π")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            self.save_results(df, output_path)
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
        else:
            print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏")
    
    def _update_dataframe_with_results(self, df: pd.DataFrame, results: List[Dict], start_idx: int) -> None:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç DataFrame –Ω–æ–≤—ã–º–∏ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏."""
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –∏—Ö –µ—â–µ –Ω–µ—Ç
        new_columns = ['fe_framework', 'state_mgmt', 'styling', 'testing', 'api_proto', 
                      'ts_required', 'business_domain', 'company_type', 'extracted_at']
        
        for col in new_columns:
            if col not in df.columns:
                if col in self.dynamic_categories:
                    df[col] = None  # JSON arrays –±—É–¥—É—Ç —Å—Ç—Ä–æ–∫–∞–º–∏
                else:
                    df[col] = None  # –°—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ vacancy_id
        for result in results:
            vacancy_id = result['vacancy_id']
            # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å –∑–∞–ø–∏—Å–∏ –≤ DataFrame
            mask = df['id'].astype(str) == vacancy_id
            
            if mask.any():
                idx = df[mask].index[0]
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Å–µ –ø–æ–ª—è
                for field, value in result.items():
                    if field != 'vacancy_id' and field in df.columns:
                        if field in self.dynamic_categories:
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Å—Å–∏–≤—ã –∫–∞–∫ JSON —Å—Ç—Ä–æ–∫–∏
                            df.at[idx, field] = json.dumps(value, ensure_ascii=False)
                        else:
                            # –°—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                            df.at[idx, field] = value
    
    def save_results(self, df: pd.DataFrame, output_path: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ parquet —Ñ–∞–π–ª."""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            import os
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ parquet
            df.to_parquet(output_path, index=False)
            print(f"üìä –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∑–∞–ø–∏—Å—è–º
            if 'extracted_at' in df.columns:
                processed_count = df['extracted_at'].notna().sum()
                print(f"üìà –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {processed_count} –∏–∑ {len(df)}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")